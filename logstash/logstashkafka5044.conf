# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
    tcp {
        host => "0.0.0.0"
            port => 5044
            mode => server
            tcp_keep_alive => true
            codec => line
            id => logstash_5044
            add_field => {
                log_name => "newdata"
            }
    }
}

filter {
    grok {
        match => {
            "message" => "(?<kafkaname>\S+?)##########(?<kafkadata>.*)"
        }
        overwrite => ["message"]
    }
}

output {
    if[kafkaname] {
        kafka {
            acks  => "1"
            batch_size => 16384
            linger_ms => 100
            request_timeout_ms => 5000
            codec => plain {
                format => "%{kafkadata}"
            }
            bootstrap_servers => "192.168.1.1:9092,192.168.1.2:9092"
            topic_id => "%{kafkaname}"
            max_request_size => 94371840
        }
    }
    else {
        file {
            path => "/data/logstash/logstash-kafkadata-5044-error-data.log"
                codec => line {
                    format => "%{+YYYY-MM-dd HH:mm:ss} --------> %{message}"
                }
        }
    }
}
